{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-box\n",
      "  Downloading python_box-7.0.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: python-box\n",
      "Successfully installed python-box-7.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install python-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from box import Box\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/mountain/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path' : path+'train_bert4rec_input.csv', # 데이터 경로\n",
    "    'max_len' : 50,\n",
    "    'hidden_units' : 50, # Embedding size\n",
    "    'num_heads' : 1, # Multi-head layer 의 수 (병렬 처리)\n",
    "    'num_layers': 2, # block의 개수 (encoder layer의 개수)\n",
    "    'dropout_rate' : 0.5, # dropout 비율\n",
    "    'lr' : 0.001,\n",
    "    'batch_size' : 16,\n",
    "    'num_epochs' : 1,\n",
    "    'num_workers' : 1,\n",
    "    'mask_prob' : 0.15, # for cloze task\n",
    "}\n",
    "\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
    "device='cuda'\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeSequenceDataSet():\n",
    "    \"\"\"\n",
    "    SequenceData 생성\n",
    "    - user : 플레이리스트\n",
    "    - item : 노래\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(self.config.data_path)\n",
    "        \n",
    "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('song_id')\n",
    "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('playlist_id')\n",
    "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
    "\n",
    "        self.df['song_idx'] = self.df['song_id'].apply(lambda x : self.item_encoder[x] + 1)\n",
    "        self.df['playlist_idx'] = self.df['playlist_id'].apply(lambda x : self.user_encoder[x])\n",
    "        self.df = self.df.sort_values(['playlist_idx', 'order']) # 순서에 따라 정렬\n",
    "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
    "\n",
    "    def generate_encoder_decoder(self, col : str) -> dict:\n",
    "        \"\"\"\n",
    "        encoder, decoder 생성\n",
    "\n",
    "        Args:\n",
    "            col (str): 생성할 columns 명\n",
    "        Returns:\n",
    "            dict: 생성된 user encoder, decoder\n",
    "        \"\"\"\n",
    "\n",
    "        encoder = {}\n",
    "        decoder = {}\n",
    "        ids = self.df[col].unique()\n",
    "\n",
    "        for idx, _id in enumerate(ids):\n",
    "            encoder[_id] = idx\n",
    "            decoder[idx] = _id\n",
    "\n",
    "        return encoder, decoder\n",
    "    \n",
    "    def generate_sequence_data(self) -> dict:\n",
    "        \"\"\"\n",
    "        sequence_data 생성\n",
    "        - user : 플레이리스트\n",
    "        - item : 노래\n",
    "\n",
    "        Returns:\n",
    "            dict: train user sequence / valid user sequence\n",
    "        \"\"\"\n",
    "        # 플리별로 노래 시퀀스 리스트업\n",
    "        users = defaultdict(list)  # 딕셔너리 value를 list로 초기화\n",
    "        user_train = {}\n",
    "        user_valid = {}\n",
    "        group_df = self.df.groupby('playlist_idx')\n",
    "        for user, item in group_df:\n",
    "            users[user].extend(item['song_idx'].tolist()) \n",
    "        \n",
    "        # 유저별로 마지막 아이템은 valid, 이전 아이템까지는 train으로 분리\n",
    "        for user in users:\n",
    "            user_train[user] = users[user][:-1]\n",
    "            user_valid[user] = [users[user][-1]] # 마지막 아이템을 예측\n",
    "\n",
    "        return user_train, user_valid\n",
    "    \n",
    "    def get_train_valid_data(self):\n",
    "        return self.user_train, self.user_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTRecDataSet(Dataset):\n",
    "    def __init__(self, user_train, max_len, num_user, num_item, mask_prob):\n",
    "        self.user_train = user_train\n",
    "        self.max_len = max_len\n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.mask_prob = mask_prob\n",
    "        self._all_items = set([i for i in range(1, self.num_item + 1)])\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 길이 (총 샘플의 수) 즉, len(dataset)을 했을 때 데이터셋의 크기를 리턴할 len\n",
    "        # 총 user(플레이리스트)의 수 = 학습에 사용할 sequence의 수\n",
    "        return self.num_user\n",
    "\n",
    "    def __getitem__(self, user): \n",
    "        # 데이터셋에서 특정 1개의 샘플을 가져오는 함수 즉, dataset[i]을 했을 때 i번째 샘플을 가져오도록 하는 인덱싱을 위한 get_item\n",
    "        user_seq = self.user_train[user]\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for s in user_seq[-self.max_len:]: # 최근 n개 아이템만 \n",
    "            prob = np.random.random() \n",
    "            if prob < self.mask_prob:\n",
    "                prob /= self.mask_prob\n",
    "                if prob < 0.8:\n",
    "                    # masking\n",
    "                    tokens.append(self.num_item + 1)  # mask_index: num_item + 1, 0: pad, 1~num_item: item index\n",
    "                elif prob < 0.9:\n",
    "                    # noise\n",
    "                    tokens.extend(self.random_neg_sampling(rated_item = user_seq, num_item_sample = 1))  # item random sampling 1개\n",
    "                else:\n",
    "                    # original\n",
    "                    tokens.append(s)\n",
    "                labels.append(s) # 학습에 사용 O\n",
    "            else:\n",
    "                tokens.append(s)\n",
    "                labels.append(0) # 학습에 사용 X\n",
    "\n",
    "        # padding\n",
    "        mask_len = self.max_len - len(tokens)\n",
    "        tokens = [0] * mask_len + tokens\n",
    "        labels = [0] * mask_len + labels\n",
    "\n",
    "        return torch.LongTensor(tokens), torch.LongTensor(labels)\n",
    "\n",
    "    def random_neg_sampling(self, rated_item : list, num_item_sample : int):\n",
    "        '''\n",
    "        플레이리스트에 없는 노래를 랜덤으로 num_item_sample 개수만큼 샘플링 \n",
    "        '''\n",
    "        nge_samples = random.sample(list(self._all_items - set(rated_item)), num_item_sample)\n",
    "        return nge_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, Q, K, V, mask):\n",
    "        \"\"\"\n",
    "        Q, K, V : (batch_size, num_heads, max_len, hidden_units)\n",
    "        mask : (batch_size, 1, max_len, max_len)\n",
    "        \"\"\"\n",
    "        attn_score = torch.matmul(Q, K.transpose(2, 3)) / math.sqrt(self.hidden_units) # (batch_size, num_heads, max_len, max_len)\n",
    "        attn_score = attn_score.masked_fill(mask == 0, -1e9)  # 유사도가 0인 지점은 -infinity로 보내 softmax 결과가 0이 되도록 함\n",
    "        attn_dist = self.dropout(F.softmax(attn_score, dim=-1))  # attention distribution\n",
    "        output = torch.matmul(attn_dist, V)  # (batch_size, num_heads, max_len, hidden_units) / # dim of output : batchSize x num_head x seqLen x hidden_units\n",
    "        return output, attn_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, hidden_units, dropout_rate):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads # head의 수\n",
    "        self.hidden_units = hidden_units\n",
    "        \n",
    "        # query, key, value, output 생성을 위해 Linear 모델 생성\n",
    "        self.W_Q = nn.Linear(hidden_units, hidden_units * num_heads, bias=False)\n",
    "        self.W_K = nn.Linear(hidden_units, hidden_units * num_heads, bias=False)\n",
    "        self.W_V = nn.Linear(hidden_units, hidden_units * num_heads, bias=False)\n",
    "        self.W_O = nn.Linear(hidden_units * num_heads, hidden_units, bias=False)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(hidden_units, dropout_rate)\n",
    "        self.dropout = nn.Dropout(dropout_rate) # dropout rate\n",
    "        self.layerNorm = nn.LayerNorm(hidden_units, 1e-6) # layer normalization\n",
    "\n",
    "    def forward(self, enc, mask):\n",
    "        \"\"\"\n",
    "        enc : (batch_size, max_len, hidden_units)\n",
    "        mask : (batch_size, 1, max_len, max_len)\n",
    "        \n",
    "        \"\"\"\n",
    "        residual = enc # residual connection을 위해 residual 부분을 저장\n",
    "        batch_size, seqlen = enc.size(0), enc.size(1)\n",
    "\n",
    "        # Query, Key, Value를 (num_head)개의 Head로 나누어 각기 다른 Linear projection을 통과시킴\n",
    "        # view() : tensor의 shape을 변경함 (batch_size, max_len, hidden_units) -> (batch_size, max_len, num_heads, hidden_units)\n",
    "        Q = self.W_Q(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units) # (batch_size, max_len, num_heads, hidden_units)\n",
    "        K = self.W_K(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units) # (batch_size, max_len, num_heads, hidden_units)\n",
    "        V = self.W_V(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units) # (batch_size, max_len, num_heads, hidden_units)\n",
    "\n",
    "        # Head별로 각기 다른 attention이 가능하도록 Transpose 후 각각 attention에 통과시킴\n",
    "        Q, K, V = Q.transpose(1, 2), K.transpose(1, 2), V.transpose(1, 2) # (batch_size, num_heads, max_len, hidden_units)\n",
    "        output, attn_dist = self.attention(Q, K, V, mask) # output : (batch_size, num_heads, max_len, hidden_units) / attn_dist : (batch_size, num_heads, max_len, max_len)\n",
    "\n",
    "        # 다시 Transpose한 후 모든 head들의 attention 결과를 합침\n",
    "        # continuous() : 가변적 메모리 할당\n",
    "        output = output.transpose(1, 2).contiguous() # (batch_size, max_len, num_heads, hidden_units) / contiguous() : 가변적 메모리 할당\n",
    "        output = output.view(batch_size, seqlen, -1) # (batch_size, max_len, hidden_units * num_heads)\n",
    "\n",
    "        # Linear Projection, Dropout, Residual sum, and Layer Normalization\n",
    "        output = self.layerNorm(self.dropout(self.W_O(output)) + residual) # (batch_size, max_len, hidden_units)\n",
    "        return output, attn_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "\n",
    "        self.W_1 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.W_2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.layerNorm = nn.LayerNorm(hidden_units, 1e-6) # layer normalization\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # Feed-Forward Network\n",
    "        output = self.W_2(F.relu(self.dropout(self.W_1(x))))\n",
    "        # Add & Norm\n",
    "        output = self.layerNorm(self.dropout(output) + residual)\n",
    "        return output\n",
    "\n",
    "\n",
    "class BERT4RecBlock(nn.Module):\n",
    "    def __init__(self, num_heads, hidden_units, dropout_rate):\n",
    "        super(BERT4RecBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads, hidden_units, dropout_rate)\n",
    "        self.pointwise_feedforward = PositionwiseFeedForward(hidden_units, dropout_rate)\n",
    "\n",
    "    def forward(self, input_enc, mask):\n",
    "        output_enc, attn_dist = self.attention(input_enc, mask)\n",
    "        output_enc = self.pointwise_feedforward(output_enc)\n",
    "        return output_enc, attn_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self, num_user, num_item, hidden_units, num_heads, num_layers, max_len, dropout_rate, device):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "\n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers \n",
    "        self.device = device\n",
    "        \n",
    "        self.item_emb = nn.Embedding(num_item + 2, hidden_units, padding_idx=0) # padding : 0 / item : 1 ~ num_item + 1 /  mask : num_item + 2\n",
    "        self.pos_emb = nn.Embedding(max_len, hidden_units) # learnable positional encoding\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.emb_layernorm = nn.LayerNorm(hidden_units, eps=1e-6)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([BERT4RecBlock(num_heads, hidden_units, dropout_rate) for _ in range(num_layers)])\n",
    "        self.out = nn.Linear(hidden_units, num_item + 1)\n",
    "    \n",
    "    def forward(self, log_seqs):\n",
    "        \"\"\"\n",
    "        log_seqs : (batch_size, max_len)\n",
    "\n",
    "        ex)\n",
    "        log_seqs = [\n",
    "                [1, 2, 3, 4, 5],\n",
    "                [0, 0, 0, 1, 2],\n",
    "                [0, 0, 1, 2, 3]\n",
    "        ]\n",
    "        \n",
    "        \"\"\"\n",
    "        seqs = self.item_emb(torch.LongTensor(log_seqs).to(self.device)) # (batch_size, max_len, hidden_units)\n",
    "        positions = np.tile(np.array(range(log_seqs.shape[1])), [log_seqs.shape[0], 1]) # log_seqs의 max_len을 (batch_size, max_len) 크기로 복사, 각 원소는 position 순서\n",
    "        seqs += self.pos_emb(torch.LongTensor(positions).to(self.device)) # (batch_size, max_len, hidden_units)\n",
    "        seqs = self.emb_layernorm(self.dropout(seqs)) # LayerNorm\n",
    "\n",
    "        # Mask for zero pad\n",
    "        # BoolTensor(log_seqs > 0) : log_seqs의 각 원소가 0보다 크면 True, 아니면 False\n",
    "        # unsqueeze(1) : (batch_size, max_len) -> (batch_size, 1, max_len)\n",
    "        # repeat(a,b,c) : 인덱스 a번째 위치에 b를 c번 반복 \n",
    "        # repeat(1, log_seqs.shape[1], 1) : (batch_size, 1, max_len) -> (batch_size, max_len, max_len)\n",
    "        mask_pad = torch.BoolTensor(log_seqs > 0).unsqueeze(1).repeat(1, log_seqs.shape[1], 1).unsqueeze(1).to(self.device) # (batch_size, 1, max_len, max_len)\n",
    "        for block in self.blocks:\n",
    "            seqs, attn_dist = block(seqs, mask_pad)\n",
    "        out = self.out(seqs) # (batch_size, max_len, num_item + 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data_loader):\n",
    "    model.train()\n",
    "    loss_val = 0\n",
    "    for seq, labels in data_loader:\n",
    "        logits = model(seq) # (batch_size, max_len, num_item + 1)\n",
    "    \n",
    "        logits = logits.view(-1, logits.size(-1)) # (batch_size * max_len, num_item + 1)\n",
    "        labels = labels.view(-1).to(device) # (batch_size * max_len)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.sqrt(criterion(logits, labels))\n",
    "\n",
    "        loss_val += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    loss_val /= len(data_loader)\n",
    "\n",
    "    return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, user_train, user_valid, max_len, bert4rec_dataset, make_sequence_dataset):\n",
    "    model.eval()\n",
    "\n",
    "    NDCG = 0.0 # NDCG@10\n",
    "    HIT = 0.0 # HIT@10\n",
    "\n",
    "    num_item_sample = 100\n",
    "\n",
    "    users = [user for user in range(make_sequence_dataset.num_user)]\n",
    "\n",
    "    for user in users:\n",
    "        seq = (user_train[user] + [make_sequence_dataset.num_item + 1])[-max_len:]\n",
    "        rated = user_train[user] + user_valid[user]\n",
    "        # negative sample 100개 샘플링\n",
    "        items = user_valid[user] + bert4rec_dataset.random_neg_sampling(rated_item = rated, num_item_sample = num_item_sample)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = -model(np.array([seq])) # predictions : seq 다음에 나올 아이템들의 확률\n",
    "            predictions = predictions[0][-1][items] # sampling\n",
    "            rank = predictions.argsort().argsort()[0].item()\n",
    "\n",
    "        if rank < 10: #Top10\n",
    "            NDCG += 1 / np.log2(rank + 2)\n",
    "            HIT += 1\n",
    "\n",
    "    NDCG /= len(users)\n",
    "    HIT /= len(users)\n",
    "\n",
    "    return NDCG, HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sequence_dataset = MakeSequenceDataSet(config = config)\n",
    "user_train, user_valid = make_sequence_dataset.get_train_valid_data()\n",
    "\n",
    "bert4rec_dataset = BERTRecDataSet(\n",
    "    user_train = user_train, \n",
    "    max_len = config.max_len, \n",
    "    num_user = make_sequence_dataset.num_user, \n",
    "    num_item = make_sequence_dataset.num_item,\n",
    "    mask_prob = config.mask_prob,\n",
    "    )\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    bert4rec_dataset, \n",
    "    batch_size = config.batch_size, \n",
    "    shuffle = True, \n",
    "    pin_memory = True,\n",
    "    num_workers = config.num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT4Rec(\n",
    "    num_user = make_sequence_dataset.num_user, \n",
    "    num_item = make_sequence_dataset.num_item, \n",
    "    hidden_units = config.hidden_units, \n",
    "    num_heads = config.num_heads, \n",
    "    num_layers = config.num_layers, \n",
    "    max_len = config.max_len, \n",
    "    dropout_rate = config.dropout_rate, \n",
    "    device = device,\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  2,  3,  4,\n",
       "          5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert4rec_dataset)\n",
    "bert4rec_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7192"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[     0,      0,      0,  ...,   2324, 549406, 615143],\n",
      "        [     0,      0,      0,  ...,   6924, 615143, 615143],\n",
      "        [     0,      0,      0,  ..., 187847,  45764,   6751],\n",
      "        ...,\n",
      "        [152248, 615143,  16453,  ..., 615143, 615143, 392826],\n",
      "        [     0,      0,      0,  ..., 397260, 170863, 186791],\n",
      "        [     0,      0,      0,  ..., 109274,  12776,  54237]]), tensor([[     0,      0,      0,  ...,      0,      0,  27311],\n",
      "        [     0,      0,      0,  ...,      0,  23391,  23392],\n",
      "        [     0,      0,      0,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [     0,  55324,      0,  ..., 346787, 375036,      0],\n",
      "        [     0,      0,      0,  ...,      0,      0,      0],\n",
      "        [     0,      0,      0,  ...,      0,      0,      0]])]\n"
     ]
    }
   ],
   "source": [
    "for x in data_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0) # label이 0인 경우 무시\n",
    "#criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1| Train loss: 3.48852| NDCG@10: 0.38014| HIT@10: 0.55645: 100%|██████████| 1/1 [1:29:31<00:00, 5371.94s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "ndcg_list = []\n",
    "hit_list = []\n",
    "for epoch in range(1, config.num_epochs + 1):\n",
    "    tbar = tqdm(range(1))\n",
    "    for _ in tbar:\n",
    "        train_loss = train(\n",
    "            model = model, \n",
    "            criterion = criterion, \n",
    "            optimizer = optimizer, \n",
    "            data_loader = data_loader)\n",
    "        \n",
    "        ndcg, hit = evaluate(\n",
    "            model = model, \n",
    "            user_train = user_train, \n",
    "            user_valid = user_valid, \n",
    "            max_len = config.max_len,\n",
    "            bert4rec_dataset = bert4rec_dataset, \n",
    "            make_sequence_dataset = make_sequence_dataset,\n",
    "            )\n",
    "\n",
    "        loss_list.append(train_loss)\n",
    "        ndcg_list.append(ndcg)\n",
    "        hit_list.append(hit)\n",
    "\n",
    "        tbar.set_description(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mountain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
